{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport seaborn as sns \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:04:50.707958Z","iopub.execute_input":"2025-08-30T19:04:50.708854Z","iopub.status.idle":"2025-08-30T19:04:51.438071Z","shell.execute_reply.started":"2025-08-30T19:04:50.708830Z","shell.execute_reply":"2025-08-30T19:04:51.437457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = \"../input/fer2013/train\" # Directory containing the training data\ntest_dir = \"../input/fer2013/test\"  # Directory containing the validation data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:04:51.439167Z","iopub.execute_input":"2025-08-30T19:04:51.439690Z","iopub.status.idle":"2025-08-30T19:04:51.443474Z","shell.execute_reply.started":"2025-08-30T19:04:51.439656Z","shell.execute_reply":"2025-08-30T19:04:51.442912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    width_shift_range = 0.1,        # Randomly shift the width of images by up to 10%\n    height_shift_range = 0.1,       # Randomly shift the height of images by up to 10%\n    horizontal_flip = True,         # Flip images horizontally at random\n    rescale = 1./255,               # Rescale pixel values to be between 0 and 1\n    validation_split = 0.2          # Set aside 20% of the data for validation\n)\n\nvalidation_datagen = ImageDataGenerator(\n    rescale = 1./255,               # Rescale pixel values to be between 0 and 1\n    validation_split = 0.2          # Set aside 20% of the data for validation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:04:51.444215Z","iopub.execute_input":"2025-08-30T19:04:51.444451Z","iopub.status.idle":"2025-08-30T19:04:51.460669Z","shell.execute_reply.started":"2025-08-30T19:04:51.444414Z","shell.execute_reply":"2025-08-30T19:04:51.459939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    directory = train_dir,           # Directory containing the training data\n    target_size = (48, 48),          # Resizes all images to 48x48 pixels\n    batch_size = 64,                 # Number of images per batch\n    color_mode = \"grayscale\",        # Converts the images to grayscale\n    class_mode = \"categorical\",      # Classifies the images into 7 categories\n    subset = \"training\"              # Uses the training subset of the data\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    directory = test_dir,            # Directory containing the validation data\n    target_size = (48, 48),          # Resizes all images to 48x48 pixels\n    batch_size = 64,                 # Number of images per batch\n    color_mode = \"grayscale\",        # Converts the images to grayscale\n    class_mode = \"categorical\",      # Classifies the images into 7 categories\n    subset = \"validation\"            # Uses the validation subset of the data\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:04:51.462453Z","iopub.execute_input":"2025-08-30T19:04:51.462872Z","iopub.status.idle":"2025-08-30T19:05:04.405039Z","shell.execute_reply.started":"2025-08-30T19:04:51.462854Z","shell.execute_reply":"2025-08-30T19:05:04.404292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define the model architecture\nmodel = Sequential()\n\n# Add a convolutional layer with 32 filters, 3x3 kernel size, and relu activation function\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n# Add a batch normalization layer\nmodel.add(BatchNormalization())\n# Add a second convolutional layer with 64 filters, 3x3 kernel size, and relu activation function\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n# Add a second batch normalization layer\nmodel.add(BatchNormalization())\n# Add a max pooling layer with 2x2 pool size\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Add a dropout layer with 0.25 dropout rate\nmodel.add(Dropout(0.25))\n\n# Add a third convolutional layer with 128 filters, 3x3 kernel size, and relu activation function\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n# Add a third batch normalization layer\nmodel.add(BatchNormalization())\n# Add a fourth convolutional layer with 128 filters, 3x3 kernel size, and relu activation function\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n# Add a fourth batch normalization layer\nmodel.add(BatchNormalization())\n# Add a max pooling layer with 2x2 pool size\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Add a dropout layer with 0.25 dropout rate\nmodel.add(Dropout(0.25))\n\n# Add a fifth convolutional layer with 256 filters, 3x3 kernel size, and relu activation function\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n# Add a fifth batch normalization layer\nmodel.add(BatchNormalization())\n# Add a sixth convolutional layer with 256 filters, 3x3 kernel size, and relu activation function\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n# Add a sixth batch normalization layer\nmodel.add(BatchNormalization())\n# Add a max pooling layer with 2x2 pool size\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Add a dropout layer with 0.25 dropout rate\nmodel.add(Dropout(0.25))\n\n# Flatten the output of the convolutional layers\nmodel.add(Flatten())\n# Add a dense layer with 256 neurons and relu activation function\nmodel.add(Dense(256, activation='relu'))\n# Add a seventh batch normalization layer\nmodel.add(BatchNormalization())\n# Add a dropout layer with 0.5 dropout rate\nmodel.add(Dropout(0.5))\n# Add a dense layer with 7 neurons (one for each class) and softmax activation function\nmodel.add(Dense(7, activation='softmax'))\n\n# Compile the model with categorical cross-entropy loss, adam optimizer, and accuracy metric\nmodel.compile(loss=\"categorical_crossentropy\", optimizer= tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:05:04.405906Z","iopub.execute_input":"2025-08-30T19:05:04.406151Z","iopub.status.idle":"2025-08-30T19:05:08.413666Z","shell.execute_reply.started":"2025-08-30T19:05:04.406134Z","shell.execute_reply":"2025-08-30T19:05:08.413061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint_callback = ModelCheckpoint(\n    filepath='emotion_cnn_model.h5',   # full model save\n    monitor='val_accuracy',\n    save_best_only=True,\n    save_weights_only=False,   # FULL MODEL\n    mode='max',\n    verbose=1\n)\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=60,\n    validation_data=validation_generator,\n    validation_steps=len(validation_generator),\n    callbacks=[checkpoint_callback]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:05:08.414350Z","iopub.execute_input":"2025-08-30T19:05:08.414569Z","iopub.status.idle":"2025-08-30T19:52:54.899739Z","shell.execute_reply.started":"2025-08-30T19:05:08.414551Z","shell.execute_reply":"2025-08-30T19:52:54.898945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the train and validation loss\nimport matplotlib.pyplot as plt\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(train_loss) + 1)\nplt.plot(epochs, train_loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:52:54.901033Z","iopub.execute_input":"2025-08-30T19:52:54.901283Z","iopub.status.idle":"2025-08-30T19:52:55.266354Z","shell.execute_reply.started":"2025-08-30T19:52:54.901263Z","shell.execute_reply":"2025-08-30T19:52:55.265638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the train and validation accuracy\ntrain_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplt.plot(epochs, train_acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:52:55.267146Z","iopub.execute_input":"2025-08-30T19:52:55.267493Z","iopub.status.idle":"2025-08-30T19:52:55.446873Z","shell.execute_reply.started":"2025-08-30T19:52:55.267462Z","shell.execute_reply":"2025-08-30T19:52:55.446230Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Get the true labels and predicted labels for the validation set\nvalidation_labels = validation_generator.classes\nvalidation_pred_probs = model.predict(validation_generator)\nvalidation_pred_labels = np.argmax(validation_pred_probs, axis=1)\n\n# Compute the confusion matrix\nconfusion_mtx = confusion_matrix(validation_labels, validation_pred_labels)\nclass_names = list(train_generator.class_indices.keys())\nsns.set()\nsns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='YlGnBu', \n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:52:55.447593Z","iopub.execute_input":"2025-08-30T19:52:55.448465Z","iopub.status.idle":"2025-08-30T19:53:00.202052Z","shell.execute_reply.started":"2025-08-30T19:52:55.448410Z","shell.execute_reply":"2025-08-30T19:53:00.201334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"emotion_cnn_model.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T19:54:23.964393Z","iopub.execute_input":"2025-08-30T19:54:23.965003Z","iopub.status.idle":"2025-08-30T19:54:24.100776Z","shell.execute_reply.started":"2025-08-30T19:54:23.964973Z","shell.execute_reply":"2025-08-30T19:54:24.099878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom tensorflow.keras.preprocessing import image\nimport os\n\n# Load the best weights from training\nmodel.load_weights(\"/kaggle/working/emotion_cnn_model.h5\")\n\n# Class labels (order should match your dataset)\nclass_labels = list(train_generator.class_indices.keys())\nprint(\"Class labels:\", class_labels)\n\n# Function to make prediction on a single image\ndef predict_image(img_path, model, target_size=(48,48)):\n    # Load image\n    img = image.load_img(img_path, target_size=target_size, color_mode=\"grayscale\")\n    img_array = image.img_to_array(img)\n    \n    # Normalize and expand dimensions\n    img_array = img_array / 255.0\n    img_array = np.expand_dims(img_array, axis=0)  # shape (1,48,48,1)\n    \n    # Predict\n    prediction = model.predict(img_array, verbose=0)\n    predicted_class = np.argmax(prediction[0])\n    confidence = np.max(prediction[0])\n    \n    return class_labels[predicted_class], confidence\n\n# Pick 10 random images from test_dir\nall_classes = os.listdir(test_dir)\nsample_images = []\n\nfor _ in range(15):\n    random_class = random.choice(all_classes)  # Actual class\n    class_dir = os.path.join(test_dir, random_class)\n    random_img = random.choice(os.listdir(class_dir))\n    sample_images.append((os.path.join(class_dir, random_img), random_class))  # save actual label too\n\n# Show predictions with actual and predicted\nplt.figure(figsize=(20,15))\n\nfor i, (img_path, actual_class) in enumerate(sample_images):\n    pred_class, conf = predict_image(img_path, model)\n    img = image.load_img(img_path, target_size=(48,48), color_mode=\"grayscale\")\n    \n    plt.subplot(3,5,i+1)   # âœ… 3 rows, 5 columns = 15 slots\n    plt.imshow(img, cmap=\"gray\")\n    plt.title(f\"Actual: {actual_class}\\nPred: {pred_class}\\nConf: {conf:.2f}\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T20:16:28.129283Z","iopub.execute_input":"2025-08-30T20:16:28.129605Z","iopub.status.idle":"2025-08-30T20:16:31.799225Z","shell.execute_reply.started":"2025-08-30T20:16:28.129581Z","shell.execute_reply":"2025-08-30T20:16:31.798282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}